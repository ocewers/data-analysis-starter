#!/usr/bin/env python
"""
Generate a data‑pipeline graph from Jupyter notebooks.

Features
--------
* Scans all notebooks under `notebooks/` for common file I/O patterns.
* Builds a directed NetworkX graph: files ⇄ notebooks.
* Emits the graph as Mermaid text which can be rendered in docs or previews.

Usage
-----
python pipeline_graph.py --root /path/to/project --out pipeline.mmd
"""

import argparse
import re
from pathlib import Path
from typing import Set, Tuple

import nbformat
import networkx as nx

MERMAID_HEADER = """%% Autogenerated by pipeline_graph.py
graph LR
    classDef notebook fill:#87CEFA,stroke:#1f4f88,stroke-width:1px,color:#000;
    classDef file fill:#D3D3D3,stroke:#555,stroke-width:1px,color:#000;
"""

# ---------------------------------------------------------------------------
# Regex patterns for I/O – extend as needed
# ---------------------------------------------------------------------------

# READ_PATTERNS = [
#    r"read_(csv|parquet|json|excel)\(\s*['\"]([^'\"]+)['\"]",  # pd.read_xxx("file")
#    r"open\(\s*['\"]([^'\"]+)['\"]",  # open("file")
# ]
# WRITE_PATTERNS = [
#    r"to_parquet\(\s*['\"]([^'\"]+)['\"]",
#    r"to_csv\(\s*['\"]([^'\"]+)['\"]",
#    r"to_json\(\s*['\"]([^'\"]+)['\"]",
#    r"to_excel\(\s*['\"]([^'\"]+)['\"]",
# ]

READ_PATTERNS = [
    r"read_(?:csv|parquet|json|excel)\([^)]*?['\"]([^'\"]+\.(?:csv|parquet|json|xlsx?|xlsm))['\"][^)]*\)",
]

WRITE_PATTERNS = [
    r"to_(?:csv|parquet|json|excel)\([^)]*?['\"]([^'\"]+\.(?:csv|parquet|json|xlsx?|xlsm))['\"][^)]*\)",
]


# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------
def extract_paths(cell_source: str, patterns) -> Set[str]:
    """Return a set of file paths matching the supplied regex patterns."""
    paths: Set[str] = set()
    for pat in patterns:
        for match in re.findall(pat, cell_source, flags=re.IGNORECASE | re.DOTALL):
            paths.add(match)
    return paths


def analyze_notebook(nb_path: Path) -> Tuple[Set[str], Set[str]]:
    """Return (inputs, outputs) discovered in a notebook."""
    nb = nbformat.read(nb_path, as_version=4)
    inputs, outputs = set(), set()

    for cell in nb.cells:
        if cell.cell_type != "code":
            continue
        src = cell.source
        inputs.update(extract_paths(src, READ_PATTERNS))
        outputs.update(extract_paths(src, WRITE_PATTERNS))

    # print all inputs and outputs for debugging
    if inputs:
        print(f"Inputs in {nb_path.name}: {', '.join(inputs)}")
    if outputs:
        print(f"Outputs in {nb_path.name}: {', '.join(outputs)}")

    return inputs, outputs


def resolve_file_node(path_str: str, project_root: Path) -> str:
    """Return a stable node identifier including path context when available."""
    path = Path(path_str)

    if path.is_absolute():
        try:
            return str(path.relative_to(project_root))
        except ValueError:
            return str(path)

    if path.parent != Path('.'):
        return str(path)

    candidate = project_root / path
    if candidate.exists():
        return str(path)

    for subdir in ("data", "output", "tests/data", "notebooks", "src", "tests"):
        candidate = project_root / subdir / path
        if candidate.exists():
            return str(Path(subdir) / path)

    for match in project_root.rglob(path.name):
        try:
            return str(match.relative_to(project_root))
        except ValueError:
            return str(match)

    return str(path)


def build_graph(project_root: Path) -> nx.DiGraph:
    """Create a directed graph of notebooks and files."""
    notebooks_dir = project_root / "notebooks"
    graph = nx.DiGraph()

    for nb_path in notebooks_dir.rglob("*.ipynb"):
        inputs, outputs = analyze_notebook(nb_path)
        nb_node = f"{nb_path.relative_to(project_root)}"
        graph.add_node(nb_node, node_type="notebook", label=nb_node)

        for in_file in inputs:
            file_node = resolve_file_node(in_file, project_root)
            graph.add_node(file_node, node_type="file", label=file_node)
            graph.add_edge(file_node, nb_node)

        for out_file in outputs:
            file_node = resolve_file_node(out_file, project_root)
            graph.add_node(file_node, node_type="file", label=file_node)
            graph.add_edge(nb_node, file_node)

    return graph


# ---------------------------------------------------------------------------
def draw_graph_mermaid(graph: nx.DiGraph, out_path: Path) -> None:
    """Render graph as Mermaid text."""
    node_ids = {node: f"n{idx}" for idx, node in enumerate(sorted(graph.nodes()), start=1)}
    lines = [MERMAID_HEADER.rstrip()]

    for node, data in graph.nodes(data=True):
        label = data["label"].replace("\"", r"\"")
        lines.append(f'    {node_ids[node]}["{label}"]')

    for src, dst in graph.edges():
        lines.append(f"    {node_ids[src]} --> {node_ids[dst]}")

    notebook_nodes = [node_ids[n] for n, data in graph.nodes(data=True) if data["node_type"] == "notebook"]
    file_nodes = [node_ids[n] for n, data in graph.nodes(data=True) if data["node_type"] == "file"]

    if notebook_nodes:
        lines.append(f"    class {','.join(notebook_nodes)} notebook;")
    if file_nodes:
        lines.append(f"    class {','.join(file_nodes)} file;")

    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
    print(f"✅ Mermaid graph written to: {out_path}")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------
def main() -> None:
    parser = argparse.ArgumentParser(
        description="Generate pipeline graph from notebooks."
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=Path("."),
        help="Project root containing data/, notebooks/ and output/ folders.",
    )
    parser.add_argument(
        "--out",
        type=Path,
        default=Path("pipeline.mmd"),
        help="Output Mermaid file (.md/.mmd).",
    )
    args = parser.parse_args()

    graph = build_graph(args.root)
    if not graph:
        print("⚠️  No notebook dependencies found.")
        return

    draw_graph_mermaid(graph, args.out)


if __name__ == "__main__":
    main()
